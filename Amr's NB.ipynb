{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting total vaccinations administered per hundred and total people vaccinated per hundred based on happiness factors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import and prepare data\n",
    "happiness = pd.read_csv('happiness.csv')\n",
    "vaccinations = pd.read_csv('country_vaccinations.csv')\n",
    "vaccinations.head()\n",
    "total_vaccinations = vaccinations.groupby('country').max()[['total_vaccinations_per_hundred', 'people_vaccinated_per_hundred']]\n",
    "merged = pd.merge(happiness, total_vaccinations, left_on='location', right_on='country').dropna()\n",
    "data = merged[['Ladder score','Logged GDP per capita',  'Social support', 'Healthy life expectancy',\n",
    "       'Freedom to make life choices', 'Generosity', 'Perceptions of corruption', 'Ladder score in Dystopia', 'Explained by: Log GDP per capita', 'Explained by: Social support',\n",
    "       'Explained by: Healthy life expectancy',\n",
    "       'Explained by: Freedom to make life choices',\n",
    "       'Explained by: Generosity', 'Explained by: Perceptions of corruption']].values\n",
    "data = StandardScaler().fit_transform(data)\n",
    "target = merged[['total_vaccinations_per_hundred',\n",
    "       'people_vaccinated_per_hundred']].values\n",
    "train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=.2, random_state=216)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 520.5692285323674\n",
      "r2: 3.4892832205479785e-05\n"
     ]
    }
   ],
   "source": [
    "# Training and Predicting model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "lin_model = LinearRegression().fit(X=train_data, y=train_target)\n",
    "predicted = lin_model.predict(test_data)\n",
    "print('MSE:', mean_squared_error(test_target, predicted))\n",
    "print('r2:', r2_score(test_target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 2}\n",
      "MSE: 466.31633124999985\n",
      "r2: 0.0853212717459052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = GridSearchCV(estimator=KNeighborsRegressor(), param_grid={'n_neighbors': range(1,30)})\n",
    "knn.fit(X=train_data, y=train_target)\n",
    "knn_predicted = knn.predict(test_data)\n",
    "print(knn.best_params_)\n",
    "print('MSE:', mean_squared_error(test_target, knn_predicted))\n",
    "print('r2:', r2_score(test_target, knn_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Degree =  2\n",
      "MSE: 5011.949209431219\n",
      "r2: -9.613458026593811\n",
      "\n",
      "\n",
      "For Degree =  3\n",
      "MSE: 4479.891749552626\n",
      "r2: -8.455276556870581\n",
      "\n",
      "\n",
      "For Degree =  4\n",
      "MSE: 911.1023092229955\n",
      "r2: -0.8704910390827177\n",
      "\n",
      "\n",
      "For Degree =  5\n",
      "MSE: 4115.653387715832\n",
      "r2: -7.305441369510589\n",
      "\n",
      "\n",
      "For Degree =  6\n",
      "MSE: 8062.783731128486\n",
      "r2: -16.009018052741585\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "for i in range(2,7):\n",
    "    deg = i\n",
    "    poly_train_data = PolynomialFeatures(deg, include_bias=False).fit_transform(train_data)\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(X=poly_train_data, y=train_target)\n",
    "    poly_test_data=PolynomialFeatures(deg, include_bias=False).fit_transform(test_data)\n",
    "    poly_predicted = poly_model.predict(poly_test_data)\n",
    "    print('For Degree = ', deg)\n",
    "    print('MSE:', mean_squared_error(test_target, poly_predicted))\n",
    "    print('r2:', r2_score(test_target, poly_predicted))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "num_loops = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tensors\n",
    "X_train = torch.from_numpy(train_data.astype(np.float32))\n",
    "y_train = torch.from_numpy(train_target.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define network\n",
    "\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear = torch.nn.Linear(14, 2)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "learning_rate = 0.0001\n",
    "l = nn.MSELoss()\n",
    "model = NeuralNetwork()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "for i in range(num_loops):\n",
    "    num_epochs = 10000 \n",
    "    for epoch in range(num_epochs):\n",
    "        #forward feed\n",
    "        y_pred = model(X_train.requires_grad_())\n",
    "\n",
    "        #calculate the loss\n",
    "        loss= l(y_pred, y_train)\n",
    "\n",
    "        #backward propagation: calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #clear out the gradients from the last step loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 485.0179357074728\n",
      "r2: 0.07741192611109121\n"
     ]
    }
   ],
   "source": [
    "# Evalutation\n",
    "nn_predicted = model(torch.from_numpy(test_data.astype(np.float32))).detach().numpy()\n",
    "print('MSE:', mean_squared_error(test_target, nn_predicted))\n",
    "print('r2:', r2_score(test_target, nn_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class MultiLayerNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLayerNeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(14, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits     \n",
    "    \n",
    "learning_rate = 0.0001\n",
    "l = nn.MSELoss()\n",
    "model = MultiLayerNeuralNetwork()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "for i in range(num_loops):\n",
    "    num_epochs = 10000\n",
    "    for epoch in range(num_epochs):\n",
    "        #forward feed\n",
    "        y_pred = model(X_train.requires_grad_())\n",
    "\n",
    "        #calculate the loss\n",
    "        loss= l(y_pred, y_train)\n",
    "\n",
    "        #backward propagation: calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #clear out the gradients from the last step loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 481.504151051936\n",
      "r2: 0.04213037788914076\n"
     ]
    }
   ],
   "source": [
    "nn_predicted = model(torch.from_numpy(test_data.astype(np.float32))).detach().numpy()\n",
    "print('MSE:', mean_squared_error(test_target, nn_predicted))\n",
    "print('r2:', r2_score(test_target, nn_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting happiness factors based on total vaccinations administered per hundred and total people vaccinated per hundred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = merged[['Ladder score','Logged GDP per capita',  'Social support', 'Healthy life expectancy',\n",
    "       'Freedom to make life choices', 'Generosity', 'Perceptions of corruption', 'Ladder score in Dystopia', 'Explained by: Log GDP per capita', 'Explained by: Social support',\n",
    "       'Explained by: Healthy life expectancy',\n",
    "       'Explained by: Freedom to make life choices',\n",
    "       'Explained by: Generosity', 'Explained by: Perceptions of corruption']].values\n",
    "target = StandardScaler().fit_transform(data)\n",
    "data = merged[['total_vaccinations_per_hundred',\n",
    "       'people_vaccinated_per_hundred']].values\n",
    "train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=.2, random_state=216)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.4764039062843939\n",
      "r2: -0.526276114382343\n"
     ]
    }
   ],
   "source": [
    "# Training and Predicting model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "model = LinearRegression().fit(X=train_data, y=train_target)\n",
    "predicted = model.predict(test_data)\n",
    "print('MSE:', mean_squared_error(test_target, predicted))\n",
    "print('r2:', r2_score(test_target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 18}\n",
      "MSE: 0.5960565996609892\n",
      "r2: 0.3699128041077059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = GridSearchCV(estimator=KNeighborsRegressor(), param_grid={'n_neighbors': range(1,30)})\n",
    "knn.fit(X=train_data, y=train_target)\n",
    "knn_predicted = knn.predict(test_data)\n",
    "print(knn.best_params_)\n",
    "print('MSE:', mean_squared_error(test_target, knn_predicted))\n",
    "print('r2:', r2_score(test_target, knn_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Degree =  2\n",
      "MSE: 81.9400242945651\n",
      "r2: -82.99236974709423\n",
      "\n",
      "\n",
      "For Degree =  3\n",
      "MSE: 6071.183247913994\n",
      "r2: -7336.014118845635\n",
      "\n",
      "\n",
      "For Degree =  4\n",
      "MSE: 919433.6248495538\n",
      "r2: -1039326.1138365762\n",
      "\n",
      "\n",
      "For Degree =  5\n",
      "MSE: 1767180753.19922\n",
      "r2: -2460787757.7068987\n",
      "\n",
      "\n",
      "For Degree =  6\n",
      "MSE: 16893327929231.135\n",
      "r2: -17531045611489.676\n",
      "\n",
      "\n",
      "For Degree =  7\n",
      "MSE: 2.2033770883780054e+17\n",
      "r2: -3.1420755999491776e+17\n",
      "\n",
      "\n",
      "For Degree =  8\n",
      "MSE: 8.290509126079196e+19\n",
      "r2: -9.755071340627401e+19\n",
      "\n",
      "\n",
      "For Degree =  9\n",
      "MSE: 2.9015136068934026e+21\n",
      "r2: -3.1514782677558116e+21\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "for i in range(2,10):\n",
    "    deg = i\n",
    "    poly_train_data = PolynomialFeatures(deg, include_bias=False).fit_transform(train_data)\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(X=poly_train_data, y=train_target)\n",
    "    poly_test_data=PolynomialFeatures(deg, include_bias=False).fit_transform(test_data)\n",
    "    poly_predicted = poly_model.predict(poly_test_data)\n",
    "    print('For Degree = ', deg)\n",
    "    print('MSE:', mean_squared_error(test_target, poly_predicted))\n",
    "    print('r2:', r2_score(test_target, poly_predicted))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tensors\n",
    "X_train = torch.from_numpy(train_data.astype(np.float32))\n",
    "y_train = torch.from_numpy(train_target.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define network\n",
    "class ReverseNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReverseNeuralNetwork, self).__init__()\n",
    "        self.linear = torch.nn.Linear(2, 14)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "learning_rate = 0.0001\n",
    "l = nn.MSELoss()\n",
    "model = ReverseNeuralNetwork()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "for i in range(num_loops):\n",
    "    num_epochs = 10000\n",
    "    for epoch in range(num_epochs):\n",
    "        #forward feed\n",
    "        y_pred = model(X_train.requires_grad_())\n",
    "\n",
    "        #calculate the loss\n",
    "        loss= l(y_pred, y_train)\n",
    "\n",
    "        #backward propagation: calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #clear out the gradients from the last step loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 5.3594893123016805\n",
      "r2: -3.9794481294065664\n"
     ]
    }
   ],
   "source": [
    "# Evalutation\n",
    "nn_predicted = model(torch.from_numpy(test_data.astype(np.float32))).detach().numpy()\n",
    "print('MSE:', mean_squared_error(test_target, nn_predicted))\n",
    "print('r2:', r2_score(test_target, nn_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class ReverseMultiLayerNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReverseMultiLayerNeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 14),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits     \n",
    "    \n",
    "learning_rate = 0.0001\n",
    "l = nn.MSELoss()\n",
    "model = ReverseMultiLayerNeuralNetwork()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "for i in range(num_loops):\n",
    "    num_epochs = 10000\n",
    "    for epoch in range(num_epochs):\n",
    "        #forward feed\n",
    "        y_pred = model(X_train.requires_grad_())\n",
    "\n",
    "        #calculate the loss\n",
    "        loss= l(y_pred, y_train)\n",
    "\n",
    "        #backward propagation: calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #clear out the gradients from the last step loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.9013502976730045\n",
      "r2: 0.027806417552400136\n"
     ]
    }
   ],
   "source": [
    "# Evalutation\n",
    "nn_predicted = model(torch.from_numpy(test_data.astype(np.float32))).detach().numpy()\n",
    "print('MSE:', mean_squared_error(test_target, nn_predicted))\n",
    "print('r2:', r2_score(test_target, nn_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
